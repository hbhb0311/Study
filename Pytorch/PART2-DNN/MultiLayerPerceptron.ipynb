{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931471824645996\n",
      "100 0.6931471824645996\n",
      "200 0.6931471824645996\n",
      "300 0.6931365728378296\n",
      "400 0.5012093782424927\n",
      "500 0.03938251733779907\n",
      "600 0.0179862380027771\n",
      "700 0.011541211977601051\n",
      "800 0.008468648418784142\n",
      "900 0.006677658297121525\n",
      "1000 0.005507137626409531\n",
      "1100 0.00468321330845356\n",
      "1200 0.004072200041264296\n",
      "1300 0.0036013040225952864\n",
      "1400 0.0032273789402097464\n",
      "1500 0.0029233861714601517\n",
      "1600 0.0026713875122368336\n",
      "1700 0.0024591770488768816\n",
      "1800 0.002278008498251438\n",
      "1900 0.0021215835586190224\n",
      "2000 0.001985180890187621\n",
      "2100 0.0018651445861905813\n",
      "2200 0.0017587037291377783\n",
      "2300 0.0016637472435832024\n",
      "2400 0.0015784635907039046\n",
      "2500 0.0015014464734122157\n",
      "2600 0.0014315582811832428\n",
      "2700 0.0013678570976480842\n",
      "2800 0.0013095646863803267\n",
      "2900 0.0012560379691421986\n",
      "3000 0.0012067091884091496\n",
      "3100 0.0011610251385718584\n",
      "3200 0.0011187163181602955\n",
      "3300 0.0010793496621772647\n",
      "3400 0.001042656134814024\n",
      "3500 0.0010083516826853156\n",
      "3600 0.0009762868285179138\n",
      "3700 0.0009461033623665571\n",
      "3800 0.000917741097509861\n",
      "3900 0.000891065807081759\n",
      "4000 0.0008658833103254437\n",
      "4100 0.0008420441881753504\n",
      "4200 0.0008195036789402366\n",
      "4300 0.0007981124217621982\n",
      "4400 0.0007778256549499929\n",
      "4500 0.000758553680498153\n",
      "4600 0.0007402218761853874\n",
      "4700 0.0007226810557767749\n",
      "4800 0.0007060057250782847\n",
      "4900 0.000690106360707432\n",
      "5000 0.0006748486775904894\n",
      "5100 0.0006602623616345227\n",
      "5200 0.0006462878664024174\n",
      "5300 0.0006329250754788518\n",
      "5400 0.0006200546631589532\n",
      "5500 0.000607736234087497\n",
      "5600 0.0005958803812973201\n",
      "5700 0.0005844570696353912\n",
      "5800 0.0005734664737246931\n",
      "5900 0.0005628935759887099\n",
      "6000 0.0005527532775886357\n",
      "6100 0.000542911293450743\n",
      "6200 0.0005333975423127413\n",
      "6300 0.0005242567276582122\n",
      "6400 0.0005154142272658646\n",
      "6500 0.0005068402388133109\n",
      "6600 0.0004985645646229386\n",
      "6700 0.0004905275418423116\n",
      "6800 0.000482759001897648\n",
      "6900 0.00047527384595014155\n",
      "7000 0.0004679677076637745\n",
      "7100 0.00046088529052212834\n",
      "7200 0.0004540116642601788\n",
      "7300 0.0004473617591429502\n",
      "7400 0.00044087591231800616\n",
      "7500 0.0004346138157416135\n",
      "7600 0.0004285008180886507\n",
      "7700 0.00042258171015419066\n",
      "7800 0.00041679682908579707\n",
      "7900 0.0004111760063096881\n",
      "8000 0.00040568935219198465\n",
      "8100 0.00040035188430920243\n",
      "8200 0.00039514864329248667\n",
      "8300 0.0003901094023603946\n",
      "8400 0.00038518948713317513\n",
      "8500 0.00038032926386222243\n",
      "8600 0.0003756628429982811\n",
      "8700 0.00037111571873538196\n",
      "8800 0.00036661335616372526\n",
      "8900 0.00036224519135430455\n",
      "9000 0.00035801128251478076\n",
      "9100 0.00035388165269978344\n",
      "9200 0.00034979681367985904\n",
      "9300 0.00034578656777739525\n",
      "9400 0.000341910490533337\n",
      "9500 0.00033812387846410275\n",
      "9600 0.0003343969292473048\n",
      "9700 0.00033078924752771854\n",
      "9800 0.0003271964960731566\n",
      "9900 0.00032372301211580634\n",
      "10000 0.0003203389933332801\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])\n",
    "\n",
    "# nn layers\n",
    "w1 = torch.Tensor(2, 2)\n",
    "b1 = torch.Tensor(2)\n",
    "w2 = torch.Tensor(2, 1)\n",
    "b2 = torch.Tensor(1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + torch.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "learning_rate = 1\n",
    "\n",
    "for step in range(10001):\n",
    "    # forward\n",
    "    l1 = torch.add(torch.matmul(X, w1), b1)\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "    Y_pred = sigmoid(l2)\n",
    "    \n",
    "    # binary cross entropy\n",
    "    cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred))\n",
    "    \n",
    "    # backprop(chain rule)\n",
    "    # loss derivative\n",
    "    d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
    "    \n",
    "    # layer2\n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_b2)\n",
    "    \n",
    "    # layer1\n",
    "    d_a1 = torch.matmul(d_b2, torch.transpose(w2, 0, 1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_b1)\n",
    "    \n",
    "    \n",
    "    # weight update\n",
    "    w1 = w1 - learning_rate * d_w1\n",
    "    b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
    "    w2 = w2 - learning_rate * d_w2\n",
    "    b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code : xor-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.709502100944519\n",
      "100 0.6932308673858643\n",
      "200 0.6930591464042664\n",
      "300 0.6927437782287598\n",
      "400 0.691247284412384\n",
      "500 0.6776837110519409\n",
      "600 0.5907617807388306\n",
      "700 0.40993380546569824\n",
      "800 0.14501768350601196\n",
      "900 0.06711645424365997\n",
      "1000 0.04173107445240021\n",
      "1100 0.029875902459025383\n",
      "1200 0.02313094027340412\n",
      "1300 0.018812065944075584\n",
      "1400 0.015822621062397957\n",
      "1500 0.013636388815939426\n",
      "1600 0.011970898136496544\n",
      "1700 0.010661439970135689\n",
      "1800 0.009605835191905499\n",
      "1900 0.008737370371818542\n",
      "2000 0.00801066868007183\n",
      "2100 0.007393894717097282\n",
      "2200 0.006864079274237156\n",
      "2300 0.0064041223376989365\n",
      "2400 0.006001196801662445\n",
      "2500 0.005645343102514744\n",
      "2600 0.005328869912773371\n",
      "2700 0.005045552738010883\n",
      "2800 0.004790512844920158\n",
      "2900 0.0045597003772854805\n",
      "3000 0.004349926486611366\n",
      "3100 0.004158392548561096\n",
      "3200 0.003982815425843\n",
      "3300 0.003821346443146467\n",
      "3400 0.003672317834571004\n",
      "3500 0.0035343635827302933\n",
      "3600 0.0034063123166561127\n",
      "3700 0.003287113970145583\n",
      "3800 0.0031759280245751143\n",
      "3900 0.003071914426982403\n",
      "4000 0.0029744734056293964\n",
      "4100 0.00288293045014143\n",
      "4200 0.0027968506328761578\n",
      "4300 0.0027156942524015903\n",
      "4400 0.002639071550220251\n",
      "4500 0.0025666533038020134\n",
      "4600 0.002498019952327013\n",
      "4700 0.002433006651699543\n",
      "4800 0.002371208742260933\n",
      "4900 0.002312462078407407\n",
      "5000 0.002256541745737195\n",
      "5100 0.0022031632252037525\n",
      "5200 0.0021522969473153353\n",
      "5300 0.00210373243317008\n",
      "5400 0.0020572913344949484\n",
      "5500 0.002012793207541108\n",
      "5600 0.0019702084828168154\n",
      "5700 0.0019293723162263632\n",
      "5800 0.0018902100855484605\n",
      "5900 0.0018525274936109781\n",
      "6000 0.0018163241911679506\n",
      "6100 0.001781510654836893\n",
      "6200 0.0017480269307270646\n",
      "6300 0.0017157236579805613\n",
      "6400 0.0016846153885126114\n",
      "6500 0.00165459793061018\n",
      "6600 0.0016256262315437198\n",
      "6700 0.0015976403374224901\n",
      "6800 0.001570610562339425\n",
      "6900 0.001544447150081396\n",
      "7000 0.001519165001809597\n",
      "7100 0.001494689262472093\n",
      "7200 0.0014709752285853028\n",
      "7300 0.0014480081154033542\n",
      "7400 0.001425697933882475\n",
      "7500 0.0014040898531675339\n",
      "7600 0.0013831385876983404\n",
      "7700 0.0013627996668219566\n",
      "7800 0.0013430282706394792\n",
      "7900 0.0013237943639978766\n",
      "8000 0.0013051428832113743\n",
      "8100 0.0012869989732280374\n",
      "8200 0.0012693328317254782\n",
      "8300 0.0012521892786026\n",
      "8400 0.0012354339705780149\n",
      "8500 0.0012191712157800794\n",
      "8600 0.0012032818049192429\n",
      "8700 0.0011878849472850561\n",
      "8800 0.0011727865785360336\n",
      "8900 0.0011580914724618196\n",
      "9000 0.0011437693610787392\n",
      "9100 0.00112979079131037\n",
      "9200 0.0011161256115883589\n",
      "9300 0.0011028186418116093\n",
      "9400 0.0010897803585976362\n",
      "9500 0.0010770853841677308\n",
      "9600 0.0010646739974617958\n",
      "9700 0.0010525460820645094\n",
      "9800 0.0010406720684841275\n",
      "9900 0.00102909654378891\n",
      "10000 0.0010177447693422437\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])\n",
    "\n",
    "# nn layers (MLP) -> 다층 퍼셉트론\n",
    "linear1 = torch.nn.Linear(2, 2, bias = True)\n",
    "linear2 = torch.nn.Linear(2, 1, bias = True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid)\n",
    "\n",
    "#define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.2568e-04],\n",
       "        [9.9914e-01],\n",
       "        [9.9872e-01],\n",
       "        [8.0427e-04]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = (hypothesis > 0.5) * 1\n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code : xor-nn-wide-deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931792497634888\n",
      "100 0.6931456327438354\n",
      "200 0.6931451559066772\n",
      "300 0.6931446194648743\n",
      "400 0.6931441426277161\n",
      "500 0.6931436657905579\n",
      "600 0.6931430697441101\n",
      "700 0.6931425333023071\n",
      "800 0.6931419968605042\n",
      "900 0.6931414604187012\n",
      "1000 0.6931408643722534\n",
      "1100 0.6931403279304504\n",
      "1200 0.6931397914886475\n",
      "1300 0.6931390762329102\n",
      "1400 0.6931384801864624\n",
      "1500 0.6931378245353699\n",
      "1600 0.6931371688842773\n",
      "1700 0.6931365132331848\n",
      "1800 0.6931357979774475\n",
      "1900 0.6931350231170654\n",
      "2000 0.6931342482566833\n",
      "2100 0.6931334733963013\n",
      "2200 0.6931325793266296\n",
      "2300 0.6931317448616028\n",
      "2400 0.6931308507919312\n",
      "2500 0.6931297779083252\n",
      "2600 0.693128764629364\n",
      "2700 0.6931276321411133\n",
      "2800 0.6931265592575073\n",
      "2900 0.6931253671646118\n",
      "3000 0.6931240558624268\n",
      "3100 0.6931227445602417\n",
      "3200 0.6931213140487671\n",
      "3300 0.6931196451187134\n",
      "3400 0.6931180357933044\n",
      "3500 0.6931161880493164\n",
      "3600 0.6931143403053284\n",
      "3700 0.6931121945381165\n",
      "3800 0.6931099891662598\n",
      "3900 0.6931074857711792\n",
      "4000 0.6931047439575195\n",
      "4100 0.6931017637252808\n",
      "4200 0.6930986046791077\n",
      "4300 0.6930950284004211\n",
      "4400 0.6930910348892212\n",
      "4500 0.6930866241455078\n",
      "4600 0.6930817365646362\n",
      "4700 0.6930761337280273\n",
      "4800 0.6930698752403259\n",
      "4900 0.6930627226829529\n",
      "5000 0.6930545568466187\n",
      "5100 0.6930450201034546\n",
      "5200 0.6930339336395264\n",
      "5300 0.6930209398269653\n",
      "5400 0.6930054426193237\n",
      "5500 0.6929867267608643\n",
      "5600 0.6929639577865601\n",
      "5700 0.692935585975647\n",
      "5800 0.6928997039794922\n",
      "5900 0.6928529739379883\n",
      "6000 0.6927908062934875\n",
      "6100 0.6927051544189453\n",
      "6200 0.6925817131996155\n",
      "6300 0.6923936605453491\n",
      "6400 0.6920852065086365\n",
      "6500 0.6915225982666016\n",
      "6600 0.6903180480003357\n",
      "6700 0.6869478225708008\n",
      "6800 0.671128511428833\n",
      "6900 0.445130318403244\n",
      "7000 0.020149610936641693\n",
      "7100 0.0067972587421536446\n",
      "7200 0.0038368997629731894\n",
      "7300 0.0026108273304998875\n",
      "7400 0.0019552677404135466\n",
      "7500 0.0015519281150773168\n",
      "7600 0.0012806989252567291\n",
      "7700 0.0010866490192711353\n",
      "7800 0.0009414979722350836\n",
      "7900 0.0008290730766020715\n",
      "8000 0.0007396105793304741\n",
      "8100 0.0006668117130175233\n",
      "8200 0.0006065426860004663\n",
      "8300 0.0005558044649660587\n",
      "8400 0.0005126275354996324\n",
      "8500 0.0004753561515826732\n",
      "8600 0.0004429460677783936\n",
      "8700 0.000414547132095322\n",
      "8800 0.0003893689136020839\n",
      "8900 0.00036700867349281907\n",
      "9000 0.0003469892544671893\n",
      "9100 0.0003288931038696319\n",
      "9200 0.0003125561634078622\n",
      "9300 0.00029771006666123867\n",
      "9400 0.0002841907844413072\n",
      "9500 0.00027175972354598343\n",
      "9600 0.0002603125758469105\n",
      "9700 0.00024980457965284586\n",
      "9800 0.00024005680461414158\n",
      "9900 0.00023099475947674364\n",
      "10000 0.00022258859826251864\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])\n",
    "\n",
    "# nn layers (MLP) -> 다층 퍼셉트론\n",
    "linear1 = torch.nn.Linear(2, 10, bias = True)\n",
    "linear2 = torch.nn.Linear(10, 10, bias = True)\n",
    "linear3 = torch.nn.Linear(10, 10, bias = True)\n",
    "linear4 = torch.nn.Linear(10, 1, bias = True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid)\n",
    "\n",
    "#define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
