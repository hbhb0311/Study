{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageFolder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sbeKKhsq2F7z2uN0P5Od_-9AP9_N-27_",
      "authorship_tag": "ABX9TyOHXNOikUe99ssU/l7erQR9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hbhb0311/Study/blob/main/Pytorch/PART3-CNN/ImageFolder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3zWyJYDHoRb"
      },
      "source": [
        "# 나만의 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCCiG6aKELWV"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er9LibLyE4mw"
      },
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NYR-53OE5wr"
      },
      "source": [
        "# 사이즈 줄이기\n",
        "trans = transforms.Compose([\n",
        "            transforms.Resize([64, 64])\n",
        "])\n",
        "train_data = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/pytorch/image', transform = trans)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWP9Yq_AFrc2",
        "outputId": "b5f2789b-1589-4a67-9ff6-eb25c1fea818"
      },
      "source": [
        "for num, value in enumerate(train_data):\n",
        "    data, label = value\n",
        "    print(num, data, label)\n",
        "\n",
        "    # imshow(data)\n",
        "    # print(label)\n",
        "    # break\n",
        "\n",
        "    if label == 0:\n",
        "        data.save('/content/drive/MyDrive/pytorch/train_data/sh/%d_%d.jpeg' %(num, label))\n",
        "    else:\n",
        "        data.save('/content/drive/MyDrive/pytorch/train_data/flower/%d_%d.jpeg' %(num, label))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765810> 0\n",
            "1 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765BD0> 0\n",
            "2 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765890> 0\n",
            "3 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765F10> 0\n",
            "4 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765C10> 0\n",
            "5 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722769B10> 0\n",
            "6 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787290> 0\n",
            "7 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787310> 0\n",
            "8 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787450> 0\n",
            "9 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787250> 0\n",
            "10 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227873D0> 0\n",
            "11 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227875D0> 0\n",
            "12 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787090> 0\n",
            "13 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787350> 0\n",
            "14 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787210> 0\n",
            "15 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787510> 0\n",
            "16 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787410> 0\n",
            "17 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787550> 0\n",
            "18 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227874D0> 0\n",
            "19 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227870D0> 0\n",
            "20 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765210> 0\n",
            "21 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765C10> 0\n",
            "22 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765210> 0\n",
            "23 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765F10> 0\n",
            "24 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765810> 0\n",
            "25 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765BD0> 0\n",
            "26 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787190> 0\n",
            "27 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787110> 0\n",
            "28 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787510> 0\n",
            "29 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787390> 0\n",
            "30 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227875D0> 0\n",
            "31 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787350> 0\n",
            "32 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787210> 0\n",
            "33 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787610> 0\n",
            "34 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787250> 0\n",
            "35 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787150> 0\n",
            "36 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787550> 0\n",
            "37 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787050> 0\n",
            "38 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722769710> 0\n",
            "39 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722769210> 0\n",
            "40 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765210> 0\n",
            "41 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765C10> 0\n",
            "42 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765BD0> 0\n",
            "43 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765410> 0\n",
            "44 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765C10> 0\n",
            "45 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765810> 0\n",
            "46 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765890> 0\n",
            "47 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787150> 0\n",
            "48 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722787250> 0\n",
            "49 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72278EB50> 0\n",
            "50 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72278EE90> 1\n",
            "51 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274FB10> 1\n",
            "52 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722863110> 1\n",
            "53 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274A550> 1\n",
            "54 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722863110> 1\n",
            "55 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722775390> 1\n",
            "56 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227EFD50> 1\n",
            "57 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722863110> 1\n",
            "58 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274A550> 1\n",
            "59 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7228DAB10> 1\n",
            "60 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7228DAC10> 1\n",
            "61 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765890> 1\n",
            "62 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227EFD50> 1\n",
            "63 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274A0D0> 1\n",
            "64 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7228DAB10> 1\n",
            "65 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722775390> 1\n",
            "66 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274A0D0> 1\n",
            "67 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274FDD0> 1\n",
            "68 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7228DAC50> 1\n",
            "69 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7228DAB10> 1\n",
            "70 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722863110> 1\n",
            "71 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274FB10> 1\n",
            "72 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722863110> 1\n",
            "73 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274A550> 1\n",
            "74 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722863110> 1\n",
            "75 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7228DAB10> 1\n",
            "76 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274A550> 1\n",
            "77 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7228DAC10> 1\n",
            "78 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765BD0> 1\n",
            "79 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274FDD0> 1\n",
            "80 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765890> 1\n",
            "81 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274A550> 1\n",
            "82 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722863110> 1\n",
            "83 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765C10> 1\n",
            "84 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274FB10> 1\n",
            "85 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227A8E90> 1\n",
            "86 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227EFD50> 1\n",
            "87 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274FB10> 1\n",
            "88 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7228DAC10> 1\n",
            "89 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274FDD0> 1\n",
            "90 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722863110> 1\n",
            "91 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722775390> 1\n",
            "92 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765890> 1\n",
            "93 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227EFD50> 1\n",
            "94 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765810> 1\n",
            "95 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722765890> 1\n",
            "96 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722863110> 1\n",
            "97 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD7227360D0> 1\n",
            "98 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD72274A550> 1\n",
            "99 <PIL.Image.Image image mode=RGB size=64x64 at 0x7FD722863110> 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNS0K3qHJ9uS"
      },
      "source": [
        "# ImageFolder2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXPDbIgrFyqA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2YI_qg3KO_-"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv-XYGlfKfbR"
      },
      "source": [
        "# 사이즈 줄이기\n",
        "trans = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "])\n",
        "train_data = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/pytorch/train_data', transform = trans)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnKYPBTTKbvi"
      },
      "source": [
        "data_loader = DataLoader(dataset = train_data, batch_size = 8, shuffle = True, num_workers = 2)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBxtu4DNLKxG"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, kernel_size = 5, stride = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(6, 16, kernel_size = 5, stride = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(16*13*13, 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg_xDh8sMoZy"
      },
      "source": [
        "# test\n",
        "net = CNN().to(device)\n",
        "test_input = (torch.Tensor(3, 3, 64, 64)).to(device)\n",
        "test_out = net(test_input)\n",
        "\n",
        "# 결과\n",
        "# torch.Size([3, 6, 30, 30])\n",
        "# torch.Size([3, 16, 13, 13])\n",
        "# torch.Size([3, 2704])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwkveXrwM3A8"
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
        "loss_func = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzwa9FbGNxte",
        "outputId": "76ae718e-2929-4b96-c677-54d3b4c9e311"
      },
      "source": [
        "total_batch = len(data_loader)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    avg_cost = 0.0\n",
        "    for num, data in enumerate(data_loader):\n",
        "        imgs, labels = data\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        out = net(imgs)\n",
        "        loss = loss_func(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += loss / total_batch\n",
        "\n",
        "    print('Epoch {} cost = {}'.format(epoch + 1, avg_cost))\n",
        "print('Learning Finished!')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 cost = 0.6942778825759888\n",
            "Epoch 2 cost = 0.6756244897842407\n",
            "Epoch 3 cost = 0.6154952645301819\n",
            "Epoch 4 cost = 0.6023144721984863\n",
            "Epoch 5 cost = 0.48735126852989197\n",
            "Epoch 6 cost = 0.32095572352409363\n",
            "Epoch 7 cost = 0.24504229426383972\n",
            "Epoch 8 cost = 0.4273144006729126\n",
            "Epoch 9 cost = 0.2260907143354416\n",
            "Epoch 10 cost = 0.2162034511566162\n",
            "Learning Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f9XWpuaTwKC"
      },
      "source": [
        "## 모델 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8ntPDhGOgUe"
      },
      "source": [
        "torch.save(net.state_dict(), '/content/drive/MyDrive/pytorch/model/model.pth')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri5zbzdyTyqF"
      },
      "source": [
        "## 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhanrbWIP78T"
      },
      "source": [
        "new_net = CNN().to(device)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVj5EH8GPj7f",
        "outputId": "e9a51e8c-9143-4540-e9c5-640a0bc38ce3"
      },
      "source": [
        "new_net.load_state_dict(torch.load('/content/drive/MyDrive/pytorch/model/model.pth')) "
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtv2HjGHP6Dl",
        "outputId": "63bb7678-69d9-47d7-9603-5180d0eb822e"
      },
      "source": [
        "print(net.layer1[0])\n",
        "print(new_net.layer1[0])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsGeLxnCT1Aa"
      },
      "source": [
        "# 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc42dPLVQDb3"
      },
      "source": [
        "trans = torchvision.transforms.Compose([\n",
        "                transforms.Resize([64, 64]),\n",
        "                transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_data = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/pytorch/test_data', transform = trans)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL9-zoEhQgiL"
      },
      "source": [
        "test_set = DataLoader(dataset = test_data, batch_size = len(test_data))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMwWigJhQpnc",
        "outputId": "d1146970-d972-4a9e-8937-a0b94be44647"
      },
      "source": [
        "with torch.no_grad():\n",
        "    for num, data in enumerate(test_set):\n",
        "        imgs, labels = data\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        prediction = net(imgs)\n",
        "        correct_prediction = torch.argmax(prediction, 1) == label\n",
        "        \n",
        "        accuracy = correct_prediction.float().mean()\n",
        "        print('Accuracy : ', accuracy.item())"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.550000011920929\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}